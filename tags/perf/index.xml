<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>perf on /dev/null</title>
    <link>https://nazavode.github.io/tags/perf/</link>
    <description>Recent content in perf on /dev/null</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://nazavode.github.io/tags/perf/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Understanding performance with Google Benchmark @ Italian C&#43;&#43; Meetup</title>
      <link>https://nazavode.github.io/blog/google-benchmark/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://nazavode.github.io/blog/google-benchmark/</guid>
      <description>&lt;p&gt;During the last meetup of the &lt;a href=&#34;https://twitter.com/italiancpp&#34;&gt;Italian C++ Community&lt;/a&gt; in
Modena, Italy I had the chance to give a talk about profiling C++ code. The whole game
boils down to &lt;em&gt;understanding&lt;/em&gt; what&amp;rsquo;s going on when you have to cope with &lt;em&gt;very smart&lt;/em&gt;
optimizing compilers, NUMA architectures and speculative, superscalar CPUs: in this quest
for knowledge we are lucky enough to have some extremely useful tools like the &lt;em&gt;holy&lt;/em&gt;
&lt;code&gt;perf&lt;/code&gt; and micro benchmarks, using the excellent
&lt;a href=&#34;https://github.com/google/benchmark&#34;&gt;Google Benchmark&lt;/a&gt; for instance.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>