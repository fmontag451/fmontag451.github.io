<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>Look ma, no CUDA! Programming GPUs with modern C&#43;&#43; and SYCL &middot; Federico Ficarelli</title>

  
  <link rel="stylesheet" href="https://nazavode.github.io/css/poole.css">
  <link rel="stylesheet" href="https://nazavode.github.io/css/hyde.css">
  <link rel="stylesheet" href="https://nazavode.github.io/css/poole-overrides.css">
  <link rel="stylesheet" href="https://nazavode.github.io/css/hyde-overrides.css">
  <link rel="stylesheet" href="https://nazavode.github.io/css/hyde-x.css">
  
  <link href="https://fonts.googleapis.com/css?family=Fira+Mono|Fira+Sans:300,300i|Raleway" rel="stylesheet">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

  
  
  
  

  <meta name="description" content="Just volatile hacks.">
  <meta name="keywords" content="hacking,development,software,python,c&#43;&#43;,c99,algorithms">
  

  
  <script src="//ajax.googleapis.com/ajax/libs/webfont/1.4.7/webfont.js"></script>
  <script>
    WebFont.load({
      google: {
        families: ['Raleway', 'Fira Sans', 'Fira Mono']
      }
    });
  </script>

</head>
<body class="theme-base-sulphur-00">
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      
      <h1>/dev/null</h1>
      
    </div>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item"><a href="https://nazavode.github.io/">Blog</a></li>
      
      <li class="sidebar-nav-item"><a href="https://nazavode.github.io/about/">About</a></li>
      
    </ul>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <a href="https://github.com/nazavode"><i class="fa fa-github-square fa-1x"></i></a>
      
      
      <a href="https://it.linkedin.com/in/fficarelli"><i class="fa fa-linkedin-square fa-1x"></i></a>
      
      
      <a href="https://twitter.com/fficarelli"><i class="fa fa-twitter-square fa-1x"></i></a>
      
      <a href="https://nazavode.github.io/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-1x"></i></a>
      </li>
    </ul>

    

    <p class="footnote">
        Powered by <a href="http://gohugo.io">Hugo</a><br/>
        &copy; 2019 Federico Ficarelli
    </p>

  </div>
</div>


<div class="content container">
  <div class="post">
    <h1 class="post-title">Look ma, no CUDA! Programming GPUs with modern C&#43;&#43; and SYCL</h1>
    <span class="post-date">Jul 21, 2019 &middot; <a href="https://nazavode.github.io/blog/sycl/#disqus_thread">Comments</a>
    
    <br/>
    <a class="label" href="https://nazavode.github.io/categories/dev">Dev</a><a class="label" href="https://nazavode.github.io/categories/talk">Talk</a>
    </span>
    

<p>Back in 2009 when I began doing real work with GPGPUs and <a href="https://en.wikipedia.org/wiki/CUDA">CUDA</a>
in the context of large scale HPC simulations, the developer experience was <em>dreadful</em>.
Sure, for the right algorithm and after lots of blood and tears, performances usually
turned out excellent. But before production, comes the poor developer. Debugging CUDA
kernels was a nightmare: whenever I had to track down a bug I had to fire up a dedicated
gaming rig (bought just for that purpose) because debuggers needed <em>two identical GPUs to
work</em> (when they actually worked, and that happened only if you spelled your prayers right
the night before). Compilers segfaulted all the time.
Generated <a href="https://en.wikipedia.org/wiki/Parallel_Thread_Execution">PTX</a>
assembly was often <em>incorrect</em> (just imagine debugging <em>correct</em> C++ code that has been
wrongly translated by your faulty compiler, on a weird hardware you can&rsquo;t really observe,
with poor tooling support).</p>

<p>On top of that depressing experience, one of the main CUDA goals was clearly to be an
<em>efficient vendor lock-in tool</em>. Once you invested effort and money on CUDA, you&rsquo;re stuck
with NVIDIA hardware.</p>

<p>Luckily, during the last ten years the GPGPU tooling ecosystem improved <em>a lot</em>. Compilers
have become stable, debuggers are now usable, we even have
<a href="https://llvm.org/docs/CompileCudaWithLLVM.html">PTX backends</a>
in toolchains other than <code>nvcc</code>, a plethora of alternative approaches emerged and keep
pushing to gain market (I would say that <a href="https://www.khronos.org/opencl/">OpenCL</a> is
the most notable one, among others).</p>

<p>In late 2018, almost ten years after my first encounter with GPGPUs, I came across this
<em>new</em> (to me) thing called <a href="https://www.khronos.org/sycl/">SYCL</a>.
The official description says:</p>

<blockquote>
<p>SYCL (pronounced <em>sickle</em>) is a royalty-free, cross-platform abstraction layer that
builds on the underlying concepts, portability and efficiency of <a href="https://www.khronos.org/opencl/">OpenCL</a>
that enables code for <strong>heterogeneous processors</strong> to be written in a <strong>single-source</strong>
style using <strong>completely standard C++</strong>. SYCL single-source programming enables the host
and kernel code for an application to be contained in the same source file, in a
<strong>type-safe</strong> way and with the simplicity of a <strong>cross-platform asynchronous task
graph</strong>.</p>
</blockquote>

<p>Sounds interesting, isn&rsquo;t it?</p>

<p>At that time I couldn&rsquo;t exactly figure out its actual adoption in the wild, was it
widespread in other markets or simply a niche thing? It was maybe <em>the next big thing</em>
that no one wanted to actually use in the real world?</p>

<p>And then this happened:</p>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Intel’s ‘One API’ Project seeks to deliver a unified programming model to simplify application development across diverse computing architectures and incorporates <a href="https://twitter.com/hashtag/SYCL?src=hash&amp;ref_src=twsrc%5Etfw">#SYCL</a> <a href="https://t.co/hJegAZ7u4E">https://t.co/hJegAZ7u4E</a> <a href="https://t.co/544wKoJj0k">pic.twitter.com/544wKoJj0k</a></p>&mdash; Khronos Group (@thekhronosgroup) <a href="https://twitter.com/thekhronosgroup/status/1141736086726750209?ref_src=twsrc%5Etfw">June 20, 2019</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>Intel announced to the world that their common programming model intended to target the
whole heterogeneous system, from GPUs to FPGAs to regular x86 CPUs, is going to be based
on SYCL. It looks like they are actively investing an interesting amount of effort on it
and they&rsquo;re doing a lot of work to
<a href="https://lists.llvm.org/pipermail/cfe-dev/2019-January/060811.html">integrate into upstream LLVM</a>
their own SYCL implementation.</p>

<p>At this point, all the experiments and prototypes I was doing during my daily job assumed
a totally different perspective.</p>

<h2 id="what-does-sycl-look-like">What does SYCL look like?</h2>

<p>For those familiar with OpenCL (and CUDA to some extent), SYCL is built on the same
concepts: it borrows the same device and execution models straight from OpenCL, which in
turn is extremely similar to CUDA. Let&rsquo;s just have a look at a simple kernel that performs
an element wise sum between containers:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#75715e">// Kernel type tag
</span><span style="color:#75715e">// Be sure to define it in an externally accessible
</span><span style="color:#75715e">// namespace (e.g.: no anonymous)
</span><span style="color:#75715e"></span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span><span style="color:#f92672">&gt;</span>
<span style="color:#66d9ef">struct</span> AddKernel {};

<span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> ContiguousContainer<span style="color:#f92672">&gt;</span>
<span style="color:#66d9ef">void</span> add(<span style="color:#66d9ef">const</span> ContiguousContainer<span style="color:#f92672">&amp;</span> a, <span style="color:#66d9ef">const</span> ContiguousContainer<span style="color:#f92672">&amp;</span> b,
         ContiguousContainer<span style="color:#f92672">&amp;</span> result) {
    <span style="color:#66d9ef">using</span> std<span style="color:#f92672">::</span>data,
          std<span style="color:#f92672">::</span>size;
    <span style="color:#66d9ef">using</span> value_type <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>remove_cv_t<span style="color:#f92672">&lt;</span>std<span style="color:#f92672">::</span>remove_reference_t<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">decltype</span>(<span style="color:#f92672">*</span>data(c))<span style="color:#f92672">&gt;&gt;</span>;
    <span style="color:#66d9ef">using</span> kernel_tag <span style="color:#f92672">=</span> AddKernel<span style="color:#f92672">&lt;</span>value_type<span style="color:#f92672">&gt;</span>;

    <span style="color:#75715e">// Queue&#39;s destructor will wait for all pending operations to complete
</span><span style="color:#75715e"></span>    cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>queue queue;

    <span style="color:#75715e">// Create buffers (views on a, b and result contiguous storage)
</span><span style="color:#75715e"></span>    cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>buffer<span style="color:#f92672">&lt;</span>value_type<span style="color:#f92672">&gt;</span> A{data(a), size(result)};
    cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>buffer<span style="color:#f92672">&lt;</span>value_type<span style="color:#f92672">&gt;</span> B{data(b), size(result)};
    cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>buffer<span style="color:#f92672">&lt;</span>value_type<span style="color:#f92672">&gt;</span> R{data(result), size(result)};

    <span style="color:#75715e">// The command group describes all setup operations needed
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// to execute the kernel on the selected device
</span><span style="color:#75715e"></span>    queue.submit([<span style="color:#f92672">&amp;</span>](cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>handler<span style="color:#f92672">&amp;</span> cgh) {
        <span style="color:#75715e">// Get proper accessors to existing buffers by specifying
</span><span style="color:#75715e"></span>        <span style="color:#75715e">// read/write intents
</span><span style="color:#75715e"></span>        <span style="color:#75715e">// (note that A, B and R are captured by reference)
</span><span style="color:#75715e"></span>        <span style="color:#66d9ef">auto</span> ka <span style="color:#f92672">=</span> A.get_access<span style="color:#f92672">&lt;</span>cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>access<span style="color:#f92672">::</span>mode<span style="color:#f92672">::</span>read<span style="color:#f92672">&gt;</span>(cgh);
        <span style="color:#66d9ef">auto</span> kb <span style="color:#f92672">=</span> B.get_access<span style="color:#f92672">&lt;</span>cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>access<span style="color:#f92672">::</span>mode<span style="color:#f92672">::</span>read<span style="color:#f92672">&gt;</span>(cgh);
        <span style="color:#66d9ef">auto</span> kr <span style="color:#f92672">=</span> R.get_access<span style="color:#f92672">&lt;</span>cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>access<span style="color:#f92672">::</span>mode<span style="color:#f92672">::</span>write<span style="color:#f92672">&gt;</span>(cgh);

        <span style="color:#75715e">// Enqueue parallel kernel
</span><span style="color:#75715e"></span>        cgh.parallel_for<span style="color:#f92672">&lt;</span>kernel_tag<span style="color:#f92672">&gt;</span>(
            cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>range<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">1</span><span style="color:#f92672">&gt;</span>{size(result)},  <span style="color:#75715e">// 1st parameter: the kernel grid
</span><span style="color:#75715e"></span>            [<span style="color:#f92672">=</span>](cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>id<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">1</span><span style="color:#f92672">&gt;</span> idx) {         <span style="color:#75715e">// 2nd parameter: the actual kernel
</span><span style="color:#75715e"></span>                <span style="color:#75715e">// We are in the kernel body:
</span><span style="color:#75715e"></span>                <span style="color:#75715e">// this is the only code that gets compiled for device(s).
</span><span style="color:#75715e"></span>                kr[idx] <span style="color:#f92672">=</span> ka[idx] <span style="color:#f92672">+</span> kb[idx];
            }
        );
    });
    <span style="color:#75715e">// At this point our kernel has been asynchronously submitted
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// for execution
</span><span style="color:#75715e"></span>
    <span style="color:#75715e">// End of current scope: before actually returning, the queue destructor
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// will block until all operations (copies and kernel executions)
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// are completed. We are sure that when the function returns all the
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// computed values have been transferred into &#39;result&#39; and are available
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// host-side.
</span><span style="color:#75715e"></span>}
</code></pre></div>
<p>From this trivial example we can make some interesting observations about the SYCL
programming model:</p>

<h4 id="modern-apis">Modern APIs</h4>

<p>Queues are drained, copies are finalized, destructors do their job: all SYCL objects are
of <a href="https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization">RAII</a> types, so
we can call it <em>modern</em> (I would call it <em>sane</em>) with respect to types design.</p>

<h4 id="just-standard-c-11">Just standard C++11</h4>

<p>Luckily enough, no weird keyword or syntax is involved, just standard C++11 code <sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup>.
Note that in the previous example all invocable objects are passed as regular lambdas.</p>

<h4 id="single-source">Single source</h4>

<p><em>Host</em> and <em>device</em> code live in the same source file. It is a SYCL implementation&rsquo;s
responsibility to split the C++ source file and forward each chunk of parsed code to the
right compilation backend (similarly to what <code>nvcc</code> does and as opposed to what OpenCL
APIs require) <sup class="footnote-ref" id="fnref:2"><a href="#fn:2">2</a></sup>.</p>

<h4 id="data-transfers-are-implicit">Data transfers are implicit</h4>

<p>Unlike CUDA and OpenCL where explicit copies are required by the model, here we just
declare our read/write intent over <code>cl::sycl::buffer</code> and the SYCL runtime deduces which
buffers have to be transferred to and from host containers <sup class="footnote-ref" id="fnref:3"><a href="#fn:3">3</a></sup>.</p>

<p>This design principle affects also the execution order of kernels: SYCL command queues are
required to be asyncronous and, while the actual execution order is unspecified, <em>data
dependencies</em> across kernels are guaranteed to be satisfied by the runtime.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#66d9ef">using</span> cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>access<span style="color:#f92672">::</span>mode<span style="color:#f92672">::</span>read,
      cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>access<span style="color:#f92672">::</span>mode<span style="color:#f92672">::</span>write,
      cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>access<span style="color:#f92672">::</span>mode<span style="color:#f92672">::</span>read_write;

cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>buffer<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> A{<span style="color:#75715e">/*...*/</span>};
cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>buffer<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> B{<span style="color:#75715e">/*...*/</span>};
cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>buffer<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> C{<span style="color:#75715e">/*...*/</span>};

cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>queue queue;

<span style="color:#75715e">// Kernel 1
</span><span style="color:#75715e"></span>queue.submit([<span style="color:#f92672">&amp;</span>](cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>handler<span style="color:#f92672">&amp;</span> cgh) {
    <span style="color:#66d9ef">auto</span> in  <span style="color:#f92672">=</span> A.get_access<span style="color:#f92672">&lt;</span>read<span style="color:#f92672">&gt;</span>(cgh);
    <span style="color:#66d9ef">auto</span> out <span style="color:#f92672">=</span> B.get_access<span style="color:#f92672">&lt;</span>write<span style="color:#f92672">&gt;</span>(cgh);
    <span style="color:#75715e">//...
</span><span style="color:#75715e"></span>}

<span style="color:#75715e">// Kernel 2
</span><span style="color:#75715e"></span>queue.submit([<span style="color:#f92672">&amp;</span>](cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>handler<span style="color:#f92672">&amp;</span> cgh) {
    <span style="color:#66d9ef">auto</span> in  <span style="color:#f92672">=</span> A.get_access<span style="color:#f92672">&lt;</span>read<span style="color:#f92672">&gt;</span>(cgh);
    <span style="color:#66d9ef">auto</span> out <span style="color:#f92672">=</span> C.get_access<span style="color:#f92672">&lt;</span>write<span style="color:#f92672">&gt;</span>(cgh);
    <span style="color:#75715e">//...
</span><span style="color:#75715e"></span>}

<span style="color:#75715e">// Kernel 3
</span><span style="color:#75715e"></span>queue.submit([<span style="color:#f92672">&amp;</span>](cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>handler<span style="color:#f92672">&amp;</span> cgh) {
    <span style="color:#66d9ef">auto</span> in    <span style="color:#f92672">=</span> B.get_access<span style="color:#f92672">&lt;</span>read<span style="color:#f92672">&gt;</span>(cgh);
    <span style="color:#66d9ef">auto</span> inout <span style="color:#f92672">=</span> C.get_access<span style="color:#f92672">&lt;</span>read_write<span style="color:#f92672">&gt;</span>(cgh);
    <span style="color:#75715e">//...
</span><span style="color:#75715e"></span>}
</code></pre></div>
<p>What the runtime does here is that it builds the <em>dependency graph</em> of our kernels based
on the <em>data dependencies</em> we implicitly declared among them by retrieving <em>accessors</em>. In
this case the runtime deduces the following dependency DAG (arrow is a <em>depends on</em>
directed relationship):</p>

<p><img src="/img/sycl-kernel-dependencies.png" alt="deps" /></p>

<p>Given this situation, the runtime <em>could</em> execute <code>Kernel 1</code> and <code>Kernel 2</code> concurrently
while the data needed by <code>Kernel 3</code> to carry out its work ensures that it is going to be
executed only after the completion of its dependencies.</p>

<p>Even in a trivial example like this where we submit a bunch of kernels, we can achieve
maximum overlapping between non-dependent data flows on the DAG implicitly deduced from
our <em>buffer accessors</em>. This looks extremely convenient compared to what happens in other
paradigms where, in real world applications, a large amount of effort must be spent to
achieve maximum overlapping between data transfers and kernel executions.</p>

<h4 id="kernels-are-launched-over-a-grid">Kernels are launched over a grid</h4>

<p>The <em>implicit iteration space</em> over which kernels are executed has shape and extent,
just like a CUDA kernel grid. Let&rsquo;s have a look at the <code>parallel_for</code> call
(ignore <code>kernel_tag</code><sup class="footnote-ref" id="fnref:4"><a href="#fn:4">4</a></sup> for now):</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp">    <span style="color:#75715e">// Enqueue parallel kernel
</span><span style="color:#75715e"></span>    cgh.parallel_for<span style="color:#f92672">&lt;</span>kernel_tag<span style="color:#f92672">&gt;</span>(
        cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>range<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">1</span><span style="color:#f92672">&gt;</span>{size(result)},  <span style="color:#75715e">// 1st parameter: the kernel grid
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// ...
</span></code></pre></div>
<p>With the first parameter we are saying that the kernel grid will have
<strong>one dimension</strong> (the non-type template parameter) with extent
<code>== size(result)</code>. In the same way as other paradigms work, with the
<code>cl::sycl::range&lt;1&gt;{n}</code> parameter we are launching a 1-dimensional vector
of execution units, one for each of the <code>n</code> output elements.</p>

<p>The SYCL standard brings so much at the stake, interesting bits like <em>device selectors</em>
(customizable objects that decide on which actual device a kernel will be executed), error
handling and reporting, n-dimensional kernel grids, device allocators, device atomics and
<em>a lot more</em>, enough to write entire books on the subject. Just stop here for now, you get
the general idea.</p>

<h2 id="challenges">Challenges</h2>

<p>As clearly <a href="https://youtu.be/KHa-OSrZPGo">pointed out by Justin Lebar</a> (one of the authors
of the clang&rsquo;s PTX backend): <em>CUDA Is a Low Level Language</em>. And that is perfectly
understandable: the accelerated portion of any application is going to be the hottest one,
that kind of hotspot that is usually carefully optimized, likely by hand, iteratively,
with the help of micro-benchmarks and packed with tricks and hacks that privilege
performance over clarity or maintenance and are obviously tightly related to the actual
hardware it targets. While SYCL claims to be <em>portable</em> and <em>cross platform</em>, just look at
the amount of extensions are being introduced to support FPGA targets
(<code>cl::sycl::vendor::xilinx::dataflow</code> for example,
<a href="https://github.com/triSYCL/triSYCL/blob/6e5565f89338a6a74d7283085da980f0c400c57e/tests/pipeline/single_task_vector_add_drt_dataflow_func_local_pipeline.cpp">here</a>
in <code>triSYCL</code>): this is completely normal since FPGAs are weird beasts, radically different
from regular GPGPU architectures and so, in hot, accelerated code this profound difference
stands out clearly.</p>

<p>I think this is going to be a recurring pattern in real world, SYCL-accelerated code
bases: a bunch of different SYCL kernels, each one hand-optimized for a class of
architectures, a single architecture or even a specific product just like happens in CUDA
or OpenCL nowadays. In other words, I would say that SYCL <del><strong>has not performance
portability among its design goals</strong></del>.</p>

<blockquote>
<p><strong><em>Errata corige</em></strong>: thanks to <a href="http://www.aerialmantis.co.uk/">Gordon Brown</a>,
who took part in the SYCL design process, I got some insights about this
topic with respect to the original design goals that have been taken into
account back in the early days.</p>

<p>Firstly, SYCL is built on top of other lower-level standards:</p>

<ul>
<li>OpenCL, from which SYCL inherits device and execution models;</li>
<li><a href="https://www.khronos.org/spir/">SPIR</a>, the intermediate representation
into which SYCL kernels are usually translated by the compiler. This sort of
<em>machine-independent assembly language</em>, similar in scope to PTX and designed
to efficiently represent massively parallel computations, is shared by other standards
like <a href="https://www.khronos.org/vulkan/">Vulkan</a> or <a href="https://www.opengl.org/">OpenGL</a>.</li>
</ul>

<p>Contrary to what I was assuming, <strong><em>performance portability</em> has been indeed considered
as a very high priority design goal</strong> but, given that:</p>

<ol>
<li>the bulk of perfomance portability is delegated to lower level building blocks
(SYCL and SPIR) that have been designed from scratch for this purpose;</li>
<li>when so diverse architectures must be taken into account, portability and performance
are inherently antithetical and a tradeoff is needed;</li>
</ol>

<p>SYCL designers aknowledged this unavoidable tradeoff and <strong>choose to fill
this gap making sure that adapting a kernel to a new hardware platform
would have been as straightforward, convenient and painless as possible</strong>.</p>
</blockquote>

<p>Despite this inevitable shortcoming, SYCL still brings a lot of advantages, for example:</p>

<ul>
<li><strong>convenience and developer <em>sanity</em></strong>: it is just standard C++ code, no
language extensions, no weird toolchains, tooling ecosystem readily available;</li>
<li><strong>host CPU backends are available from day one</strong>: they enable the applications to leverage
<em>both</em> the host CPU and discrete accelerators and, maybe important alike, they provide
easy debugging, observability and seamless deployment (e.g. you don&rsquo;t have to buy some
beefy gaming laptop just to be able to develop your stuff);</li>
<li><strong>a terse, modern and expressive API</strong>, miles ahead of the sheer verbosity of OpenCL;</li>
<li><strong>no vendor-lock in</strong>: your code can be run almost everywhere, from CPU-only and
accelerated servers to Android phones. Even if NVIDIA could try to gatekeep
<a href="https://www.khronos.org/registry/spir-v/">SPIR-V</a> support on their own platform,
when in presence of CUDA hardware the compiler could just sidestep SPIR-V generation and
go directly for the PTX backend to natively compile SYCL kernels for NVIDIA hardware 😎 <sup class="footnote-ref" id="fnref:5"><a href="#fn:5">5</a></sup>.</li>
</ul>

<p>Moreover, several open and closed source implementations are already available,
each one with its goals and strenghts:</p>

<ul>
<li><a href="https://github.com/triSYCL/triSYCL">triSYCL</a>, the reference implementation;</li>
<li><a href="https://github.com/illuhad/hipSYCL">hipSYCL</a>;</li>
<li><a href="https://www.codeplay.com/products/computesuite/computecpp">ComputeCpp</a>;</li>
<li><a href="https://github.com/intel/llvm/tree/sycl">clang</a>, actively developed by Intel
and aimed at being reintegrated in upstream LLVM.</li>
</ul>

<p>To summarize the ecosystem, I will borrow this chart directly from the
<a href="https://github.com/illuhad/hipSYCL">hipSYCL</a> documentation:</p>

<p><img src="/img/sycl-targets.png" alt="targets" /></p>

<p>Wrapping up, I personally think that the first, realistic, valuable goal that SYCL can
achieve is to estabilish both <strong>a standard platform and a common vocabulary for
heterogeneous systems programming</strong> on which people coming from different industries and
backgrounds can build communities, share code, tooling, build systems and, more
importantly, <strong>break out from vendor lock-ins</strong>.</p>

<p>Of course, the most important question right now is:</p>

<p><em>Will it succeed?</em></p>

<h2 id="look-ma-no-cuda-programming-gpus-with-modern-c-italian-c-meetup">Look ma, no CUDA! Programming GPUs with modern C++ @ Italian C++ Meetup</h2>

<p>During the <a href="https://www.italiancpp.org/event/meetup-maggio2019/">May 2019 meetup</a>
of the <a href="https://twitter.com/italiancpp">Italian C++ Community</a>
in Modena, I gave an introductory talk about the state of the art in GPGPU programming,
the paradigms that emerged in the last ten years and what SYCL brings to the table and why
we should care. You can find all the support material including examples, build scripts
and the slide deck <a href="https://github.com/nazavode/meetupcpp-may-2019">here</a>, feel free to
grab anything you happen to find useful. You can even see me prattle on (<strong>sorry, italian
only</strong>) <a href="https://www.youtube.com/watch?v=c04Y9AUH-xU">here</a>.</p>

<p>Thanks to all the attendees and to <a href="https://twitter.com/ilpropheta">Marco Arena</a>
for the chance to show some brand new cool stuff!</p>

<h2 id="credits">Credits</h2>

<p>A lot of excellent charts, snippets and pitches have been taken directly from publicly
available talks across the net, I&rsquo;ve strived really hard to put proper credits but if you
notice that something&rsquo;s missing please drop a comment or open an issue on
<a href="https://www.italiancpp.org/event/meetup-maggio2019/">the repo</a>.</p>

<p>I&rsquo;m particularly grateful to (in order of appearance during the talk):</p>

<ul>
<li><a href="https://www.karlrupp.net/">Karl Rupp</a></li>
<li><a href="https://wongmichael.com/about/">Michael Wong</a></li>
<li><a href="http://www.aerialmantis.co.uk/">Gordon Brown</a></li>
<li><a href="https://github.com/illuhad">Aksel Alpay</a></li>
</ul>

<p><em>Thank you folks for your help in making my slides more clear and understandable</em>.</p>

<h2 id="resources">Resources</h2>

<ul>
<li><a href="http://sycl.tech/"><code>sycl.tech</code></a>: a comprehensive community platform that collects articles, blog posts, talks and everything related to SYCL that shows up on the web.</li>
<li><a href="https://blog.tartanllama.xyz/sycl/">Accelerating your C++ on GPU with SYCL by Simon Brand</a> - one of the nicest introductions around.</li>
<li><a href="http://cppedinburgh.uk/slides/201607-sycl.pdf">Programming GPUs with SYCL by Gordon Brown</a> - a great introduction to the whys and hows of SYCL.</li>
<li><a href="https://developer.codeplay.com/products/computecpp/ce/guides/sycl-guide?">SYCL Developer Guide by Codeplay</a> - the current lack of learning learning material about SYCL is appalling but this terse developer guide makes the situation a little better.</li>
<li><a href="https://github.com/AerialMantis/cppcon2018-parallelism-class">CppCon 2018: Parallel Programming with Modern C++ by Gordon Brown</a> - a great overview of parallel programming and modern C++.</li>
<li><a href="https://www.khronos.org/assets/uploads/developers/library/2018-evs/EVS2018_09_Modern_Cpp_for_accelerators_andrew.pdf">Modern C++ for accelerators: a SYCL deep dive by Andrew Richards</a> - an excellent slide deck to be printed and studied.</li>
<li><a href="https://youtu.be/rfg19iODkhI">2019 EuroLLVM Developers’ Meeting: A. Savonichev (Intel) &ldquo;SYCL compiler: zero-cost abstraction and type safety for heterogeneous computing&rdquo;</a> - a nice insight on how Intel is working on his own SYCL implementation for LLVM; mandatory for compiler nerds.</li>
<li><a href="https://www.khronos.org/files/sycl/sycl-12-reference-card.pdf">SYCL 1.2.1 API Reference Card</a> - print and hang it on the wall next to the Picasso you just bought at Sotheby&rsquo;s.</li>
<li><a href="https://www.khronos.org/registry/SYCL/">SYCL Standard Specification</a> - to be a proper standard, you need a proper spec. Not so <em>standardese</em> (a traightforward and educational read, actually) but definitely not a novel.</li>
<li><a href="https://gcc.gnu.org/wiki/Offloading">GCC support for offloading to PTX via OpenACC</a></li>
<li><a href="https://llvm.org/docs/CompileCudaWithLLVM.html">Compiling CUDA with clang - LLVM 9 documentation</a></li>
<li><a href="https://youtu.be/KHa-OSrZPGo">CppCon 2016: CUDA is a low-level language by Justin Lebar</a></li>
<li><a href="https://ai.google/research/pubs/pub45226"><code>gpucc</code>: An Open-Source GPGPU Compiler</a></li>
<li><a href="https://arxiv.org/pdf/1904.05347.pdf">John Lawson et al., Cross-Platform Performance Portability Using Highly Parametrized SYCL Kernels</a> - a very nice article about parametrizing SYCL kernels to achieve good <em>performance portability</em> across architectures.</li>
</ul>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1"><p>the SYCL specification is actually based on C++11 but this restriction applies only
to the body of the kernel lambda, e.g. the only code that is going to be actually
compiled by device backends. In the example I used some C++17 library stuff
(<a href="https://en.cppreference.com/w/cpp/iterator/data"><code>std::data()</code></a> for instance),
and it is ok as long as the host frontend supports it.</p>
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>

<li id="fn:2"><p>while totally invisible to the user, the standard specification allows
  two different workflows for compilation:</p>

<ul>
<li><em>separate compilation</em>: a frontend driver splits the C++ source and calls
different device compilers under the hood before linking everything together
in a fat binary;</li>
<li><em>single source compilation</em>: the actual compiler frontend parses the input
translation unit just once (remember that we are dealing just with standard
C++11 code) and then forwards the lowered representation to all the device
backends involved.
For example, <a href="https://github.com/illuhad/hipSYCL">hipSYCL</a> used to rely on
<em>separate compilation</em> using a
<a href="https://github.com/illuhad/hipSYCL/blob/master/bin/syclcc">python script</a>
to carry out all the orchestration work before switching to the
<em>single source compilation</em> strategy via the
<a href="https://github.com/illuhad/hipSYCL/blob/master/bin/syclcc-clang">clang plugin interface</a>.</li>
</ul>
 <a class="footnote-return" href="#fnref:2"><sup>[return]</sup></a></li>

<li id="fn:3"><p>since we are constructing <em>non-owning views</em> (<code>cl::sycl::buffer&lt;T&gt;</code> acts exactly
like a <a href="https://en.cppreference.com/w/cpp/container/span"><code>std::span&lt;T&gt;</code></a> in this regard)
over contiguous chunks of memory that have to be transferred across different address
spaces, make sure that the
<a href="https://en.cppreference.com/w/cpp/named_req/ContiguousContainer"><code>ContiguousContainer</code> concept</a>
is satisfied: while we wait for C++20 to bring proper concepts in, we can
reasonably ensure the <em>contiguous sequence</em> (e.g.: <em>contiguous storage</em>)
property just like
<a href="https://github.com/microsoft/GSL/blob/1212beae777dba02c230ece8c0c0ec12790047ea/include/gsl/span#L419-L426"><code>GSL</code> does for <code>gsl::span&lt;T&gt;</code></a>).</p>
 <a class="footnote-return" href="#fnref:3"><sup>[return]</sup></a></li>

<li id="fn:4"><p>the <code>parallel_for</code> template is instantiated on an (empty) type,
in this case called <code>class AddKernel</code>. This <em>tag</em> is used only to give the
anonymous callable object generated by the lambda expression a unique,
user-defined name on which (possibly) different compilers can agree on.
Look at it as workaround to de-anonymize compiler-generated callable
objects (or a way to have <code>extern</code> lambdas).
Please note that the tag itself is templatized on the <code>value_type</code>
of containers: each kernel template instantiation <em>must be different</em>, in
other words <strong>be aware that kernels are just regular functions and so
they must abide by <a href="https://en.wikipedia.org/wiki/One_Definition_Rule">ODR</a>!</strong></p>
 <a class="footnote-return" href="#fnref:4"><sup>[return]</sup></a></li>

<li id="fn:5"><p>in the original <a href="https://ai.google/research/pubs/pub45226"><code>gpucc</code> paper</a>, Google
  claims that their open source PTX backend (now
  <a href="https://llvm.org/docs/CompileCudaWithLLVM.html">merged in upstream LLVM</a>)
  is either on par or outperforms <code>nvcc</code> for all the workloads they took
  into account.</p>
 <a class="footnote-return" href="#fnref:5"><sup>[return]</sup></a></li>
</ol>
</div>

  </div>
  <div id="disqus_thread"></div>
</div>


<script type="text/javascript">
var disqus_shortname = "nazavodeio";
(function () {
    var s = document.createElement('script'); s.async = true;
    s.type = 'text/javascript';
    s.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>



<script type="text/javascript">
    var disqus_shortname = "nazavodeio";
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


</body>
</html>

