<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.55.6" />
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>/dev/null &middot; Federico Ficarelli</title>

  
  <link rel="stylesheet" href="https://nazavode.github.io/css/poole.css">
  <link rel="stylesheet" href="https://nazavode.github.io/css/hyde.css">
  <link rel="stylesheet" href="https://nazavode.github.io/css/poole-overrides.css">
  <link rel="stylesheet" href="https://nazavode.github.io/css/hyde-overrides.css">
  <link rel="stylesheet" href="https://nazavode.github.io/css/hyde-x.css">
  
  <link href="https://fonts.googleapis.com/css?family=Fira+Mono|Fira+Sans:300,300i|Raleway" rel="stylesheet">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

  
  
  
  <link href="https://nazavode.github.io/index.xml" rel="alternate" type="application/rss+xml" title="/dev/null &middot; Federico Ficarelli" />

  <meta name="description" content="Just volatile hacks.">
  <meta name="keywords" content="hacking,development,software,python,c&#43;&#43;,c99,algorithms">
  

  
  <script src="//ajax.googleapis.com/ajax/libs/webfont/1.4.7/webfont.js"></script>
  <script>
    WebFont.load({
      google: {
        families: ['Raleway', 'Fira Sans', 'Fira Mono']
      }
    });
  </script>

</head>
<body class="theme-base-sulphur-00">
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      
      <h1>/dev/null</h1>
      
    </div>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item"><a href="https://nazavode.github.io/">Blog</a></li>
      
      <li class="sidebar-nav-item"><a href="https://nazavode.github.io/about/">About</a></li>
      
    </ul>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <a href="https://github.com/nazavode"><i class="fa fa-github-square fa-1x"></i></a>
      
      
      <a href="https://it.linkedin.com/in/fficarelli"><i class="fa fa-linkedin-square fa-1x"></i></a>
      
      
      <a href="https://twitter.com/fficarelli"><i class="fa fa-twitter-square fa-1x"></i></a>
      
      <a href="https://nazavode.github.io/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-1x"></i></a>
      </li>
    </ul>

    

    <p class="footnote">
        Powered by <a href="http://gohugo.io">Hugo</a><br/>
        &copy; 2019 Federico Ficarelli
    </p>

  </div>
</div>


<div class="content container">
  <div class="posts">
    
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://nazavode.github.io/blog/sycl/">Look ma, no CUDA! Programming GPUs with modern C&#43;&#43; and SYCL</a>
      </h1>
      <span class="post-date">Jul 21, 2019 &middot; <a href="https://nazavode.github.io/blog/sycl/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://nazavode.github.io/categories/dev">Dev</a><a class="label" href="https://nazavode.github.io/categories/talk">Talk</a>
      </span>
      
      

<p>Back in 2009 when I began doing real work with GPGPUs and <a href="https://en.wikipedia.org/wiki/CUDA">CUDA</a>
in the context of large scale HPC simulations, the developer experience was <em>dreadful</em>.
Sure, for the right algorithm and after lots of blood and tears, performances usually
turned out excellent. But before production, comes the poor developer. Debugging CUDA
kernels was a nightmare: whenever I had to track down a bug I had to fire up a dedicated
gaming rig (bought just for that purpose) because debuggers needed <em>two identical GPUs to
work</em> (when they actually worked, and that happened only if you spelled your prayers right
the night before). Compilers segfaulted all the time.
Generated <a href="https://en.wikipedia.org/wiki/Parallel_Thread_Execution">PTX</a>
assembly was often <em>incorrect</em> (just imagine debugging <em>correct</em> C++ code that has been
wrongly translated by your faulty compiler, on a weird hardware you can&rsquo;t really observe,
with poor tooling support).</p>

<p>On top of that depressing experience, one of the main CUDA goals was clearly to be an
<em>efficient vendor lock-in tool</em>. Once you invested effort and money on CUDA, you&rsquo;re stuck
with NVidia hardware.</p>

<p>Luckily, during the last ten years the GPGPU tooling ecosystem improved <em>a lot</em>. Compilers
have become stable, debuggers are now usable, we even have
<a href="https://llvm.org/docs/CompileCudaWithLLVM.html">PTX backends</a>
in toolchains other than <code>nvcc</code>, a plethora of alternative approaches emerged and keep
struggling to gain market (I would say that <a href="https://www.khronos.org/opencl/">OpenCL</a> is
the most notable one, among others).</p>

<p>In late 2018, almost ten years after my first encounter with GPGPUs, I came across this
<em>new</em> (to me) thing called <a href="https://www.khronos.org/sycl/">SYCL</a>.
The official description says:</p>

<blockquote>
<p>SYCL (pronounced <em>sickle</em>) is a royalty-free, cross-platform abstraction layer that
builds on the underlying concepts, portability and efficiency of <a href="https://www.khronos.org/opencl/">OpenCL</a>
that enables code for <strong>heterogeneous processors</strong> to be written in a <strong>single-source</strong>
style using <strong>completely standard C++</strong>. SYCL single-source programming enables the host
and kernel code for an application to be contained in the same source file, in a
<strong>type-safe</strong> way and with the simplicity of a <strong>cross-platform asynchronous task
graph</strong>.</p>
</blockquote>

<p>Sounds interesting, isn&rsquo;t it?</p>

<p>At that time I couldn&rsquo;t exactly figure out its actual adoption in the wild, was it
widespread in other markets or simply a niche thing? It was maybe <em>the next big thing</em>
that no one wanted to actually use in the real world?</p>

<p>And then this happened:</p>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Intel’s ‘One API’ Project seeks to deliver a unified programming model to simplify application development across diverse computing architectures and incorporates <a href="https://twitter.com/hashtag/SYCL?src=hash&amp;ref_src=twsrc%5Etfw">#SYCL</a> <a href="https://t.co/hJegAZ7u4E">https://t.co/hJegAZ7u4E</a> <a href="https://t.co/544wKoJj0k">pic.twitter.com/544wKoJj0k</a></p>&mdash; Khronos Group (@thekhronosgroup) <a href="https://twitter.com/thekhronosgroup/status/1141736086726750209?ref_src=twsrc%5Etfw">June 20, 2019</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>Intel announced to the world that their common programming model intended to target the
whole heterogeneous system, from GPUs to FPGAs to regular x86 CPUs, is going to be based
on SYCL. It looks like they are actively investing an interesting amount of effort on it
and they&rsquo;re doing a lot of work to
<a href="https://lists.llvm.org/pipermail/cfe-dev/2019-January/060811.html">integrate into upstream LLVM</a>
their own SYCL implementation.</p>

<p>At this point, all the experiments and prototypes I was doing during my daily job assumed
a totally different perspective.</p>

<h2 id="what-does-sycl-look-like">What does SYCL look like?</h2>

<p>For those familiar with OpenCL (and CUDA to some extent), SYCL is built on the same
concepts: it borrows the same device and execution models straight from OpenCL, which in
turn is extremely similar to CUDA. Let&rsquo;s just have a look at a simple kernel that performs
an element wise sum between containers:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#75715e">// Kernel type tag
</span><span style="color:#75715e">// Be sure to define it in an externally accessible
</span><span style="color:#75715e">// namespace (e.g.: no anonymous)
</span><span style="color:#75715e"></span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span><span style="color:#f92672">&gt;</span>
<span style="color:#66d9ef">struct</span> AddKernel {};

<span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> ContiguousContainer<span style="color:#f92672">&gt;</span>
<span style="color:#66d9ef">void</span> add(<span style="color:#66d9ef">const</span> ContiguousContainer<span style="color:#f92672">&amp;</span> a, <span style="color:#66d9ef">const</span> ContiguousContainer<span style="color:#f92672">&amp;</span> b,
         ContiguousContainer<span style="color:#f92672">&amp;</span> result) {
    <span style="color:#66d9ef">using</span> std<span style="color:#f92672">::</span>data,
          std<span style="color:#f92672">::</span>size;
    <span style="color:#66d9ef">using</span> value_type <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>remove_cv_t<span style="color:#f92672">&lt;</span>std<span style="color:#f92672">::</span>remove_reference_t<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">decltype</span>(<span style="color:#f92672">*</span>data(c))<span style="color:#f92672">&gt;&gt;</span>;
    <span style="color:#66d9ef">using</span> kernel_tag <span style="color:#f92672">=</span> AddKernel<span style="color:#f92672">&lt;</span>value_type<span style="color:#f92672">&gt;</span>;

    <span style="color:#75715e">// Queue&#39;s destructor will wait for all pending operations to complete
</span><span style="color:#75715e"></span>    cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>queue queue;

    <span style="color:#75715e">// Create buffers (views on a, b and result contiguous storage)
</span><span style="color:#75715e"></span>    cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>buffer<span style="color:#f92672">&lt;</span>value_type<span style="color:#f92672">&gt;</span> A{data(a), size(result)};
    cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>buffer<span style="color:#f92672">&lt;</span>value_type<span style="color:#f92672">&gt;</span> B{data(b), size(result)};
    cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>buffer<span style="color:#f92672">&lt;</span>value_type<span style="color:#f92672">&gt;</span> R{data(result), size(result)};

    <span style="color:#75715e">// The command group describes all setup operations needed
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// to execute the kernel on the selected device
</span><span style="color:#75715e"></span>    queue.submit([<span style="color:#f92672">&amp;</span>](cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>handler<span style="color:#f92672">&amp;</span> cgh) {
        <span style="color:#75715e">// Get proper accessors to existing buffers by specifying
</span><span style="color:#75715e"></span>        <span style="color:#75715e">// read/write intents
</span><span style="color:#75715e"></span>        <span style="color:#75715e">// (note that A, B and R are captured by reference)
</span><span style="color:#75715e"></span>        <span style="color:#66d9ef">auto</span> ka <span style="color:#f92672">=</span> A.get_access<span style="color:#f92672">&lt;</span>cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>access<span style="color:#f92672">::</span>mode<span style="color:#f92672">::</span>read<span style="color:#f92672">&gt;</span>(cgh);
        <span style="color:#66d9ef">auto</span> kb <span style="color:#f92672">=</span> B.get_access<span style="color:#f92672">&lt;</span>cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>access<span style="color:#f92672">::</span>mode<span style="color:#f92672">::</span>read<span style="color:#f92672">&gt;</span>(cgh);
        <span style="color:#66d9ef">auto</span> kr <span style="color:#f92672">=</span> R.get_access<span style="color:#f92672">&lt;</span>cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>access<span style="color:#f92672">::</span>mode<span style="color:#f92672">::</span>write<span style="color:#f92672">&gt;</span>(cgh);

        <span style="color:#75715e">// Enqueue parallel kernel
</span><span style="color:#75715e"></span>        cgh.parallel_for<span style="color:#f92672">&lt;</span>kernel_tag<span style="color:#f92672">&gt;</span>(
            cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>range<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">1</span><span style="color:#f92672">&gt;</span>{size(result)},  <span style="color:#75715e">// 1st paramater: the kernel grid
</span><span style="color:#75715e"></span>            [<span style="color:#f92672">=</span>](cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>id<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">1</span><span style="color:#f92672">&gt;</span> idx) {         <span style="color:#75715e">// 2nd paramater: the actual kernel
</span><span style="color:#75715e"></span>                <span style="color:#75715e">// We are in the kernel body:
</span><span style="color:#75715e"></span>                <span style="color:#75715e">// this is the only code that gets compiled for device(s).
</span><span style="color:#75715e"></span>                kr[idx] <span style="color:#f92672">=</span> ka[idx] <span style="color:#f92672">+</span> kb[idx];
            }
        );
    });
    <span style="color:#75715e">// At this point our kernel has been asynchronously submitted
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// for execution
</span><span style="color:#75715e"></span>
    <span style="color:#75715e">// End of current scope: before actually returning, the queue destructor
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// will block until all operations (copies and kernel executions)
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// are completed. We are sure that when the function returns all the
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// computed values have been transferred into &#39;result&#39; and are available
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// host-side.
</span><span style="color:#75715e"></span>}
</code></pre></div>
<p>From this trivial example we can make some interesting observations about the SYCL
programming model:</p>

<h4 id="modern-apis">Modern APIs</h4>

<p>Queues are drained, copies are finalized, destructors do their job: all SYCL objects are
of <a href="https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization">RAII</a> types, so
we can call it <em>modern</em> (I would call it <em>sane</em>) with respect to types design.</p>

<h4 id="just-standard-c-11">Just standard C++11</h4>

<p>Luckily enough, no weird keyword or syntax is involved, just standard C++11 code <sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup>.
Note that in the previous example all invocable objects are passed as regular lambdas.</p>

<h4 id="single-source">Single source</h4>

<p><em>Host</em> and <em>device</em> code live in the same source file. It is a SYCL implementation&rsquo;s
responsibility to split the C++ source file and forward each chunk of parsed code to the
right compilation backend (similarly to what <code>nvcc</code> does and as opposed to what OpenCL
APIs require) <sup class="footnote-ref" id="fnref:2"><a href="#fn:2">2</a></sup>.</p>

<h4 id="data-transfers-are-implicit">Data transfers are implicit</h4>

<p>Unlike CUDA and OpenCL where explicit copies are required by the model, here we just
declare our read/write intent over <code>cl::sycl::buffer</code> and the SYCL runtime deduces which
buffers have to be transferred to and from host containers <sup class="footnote-ref" id="fnref:3"><a href="#fn:3">3</a></sup>.</p>

<p>This design principle affects also the execution order of kernels: SYCL command queues are
required to be asyncronous and, while the actual execution order is unspecified, <em>data
dependencies</em> across kernels are guaranteed to be satisfied by the runtime.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#66d9ef">using</span> cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>access<span style="color:#f92672">::</span>mode<span style="color:#f92672">::</span>read,
      cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>access<span style="color:#f92672">::</span>mode<span style="color:#f92672">::</span>write,
      cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>access<span style="color:#f92672">::</span>mode<span style="color:#f92672">::</span>read_write;

cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>buffer<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> A{<span style="color:#75715e">/*...*/</span>};
cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>buffer<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> B{<span style="color:#75715e">/*...*/</span>};
cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>buffer<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> C{<span style="color:#75715e">/*...*/</span>};

cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>queue queue;

<span style="color:#75715e">// Kernel 1
</span><span style="color:#75715e"></span>queue.submit([<span style="color:#f92672">&amp;</span>](cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>handler<span style="color:#f92672">&amp;</span> cgh) {
    <span style="color:#66d9ef">auto</span> in  <span style="color:#f92672">=</span> A.get_access<span style="color:#f92672">&lt;</span>read<span style="color:#f92672">&gt;</span>(cgh);
    <span style="color:#66d9ef">auto</span> out <span style="color:#f92672">=</span> B.get_access<span style="color:#f92672">&lt;</span>write<span style="color:#f92672">&gt;</span>(cgh);
    <span style="color:#75715e">//...
</span><span style="color:#75715e"></span>}

<span style="color:#75715e">// Kernel 2
</span><span style="color:#75715e"></span>queue.submit([<span style="color:#f92672">&amp;</span>](cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>handler<span style="color:#f92672">&amp;</span> cgh) {
    <span style="color:#66d9ef">auto</span> in  <span style="color:#f92672">=</span> A.get_access<span style="color:#f92672">&lt;</span>read<span style="color:#f92672">&gt;</span>(cgh);
    <span style="color:#66d9ef">auto</span> out <span style="color:#f92672">=</span> C.get_access<span style="color:#f92672">&lt;</span>write<span style="color:#f92672">&gt;</span>(cgh);
    <span style="color:#75715e">//...
</span><span style="color:#75715e"></span>}

<span style="color:#75715e">// Kernel 3
</span><span style="color:#75715e"></span>queue.submit([<span style="color:#f92672">&amp;</span>](cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>handler<span style="color:#f92672">&amp;</span> cgh) {
    <span style="color:#66d9ef">auto</span> in    <span style="color:#f92672">=</span> B.get_access<span style="color:#f92672">&lt;</span>read<span style="color:#f92672">&gt;</span>(cgh);
    <span style="color:#66d9ef">auto</span> inout <span style="color:#f92672">=</span> C.get_access<span style="color:#f92672">&lt;</span>read_write<span style="color:#f92672">&gt;</span>(cgh);
    <span style="color:#75715e">//...
</span><span style="color:#75715e"></span>}
</code></pre></div>
<p>What the runtime does here is that it builds the <em>dependency graph</em> of our kernels based
on the <em>data dependencies</em> we implicitly declared among them by retrieving <em>accessors</em>. In
this case the runtime deduces the following dependency DAG (arrow is a <em>depends on</em>
directed relationship):</p>

<p><img src="/img/sycl-kernel-dependencies.png" alt="deps" /></p>

<p>Given this situation, the runtime <em>could</em> execute <code>Kernel 1</code> and <code>Kernel 2</code> concurrently
while the data needed by <code>Kernel 3</code> to carry out its work ensures that it is going to be
executed only after the completion of its dependencies.</p>

<p>Even in a trivial example like this where we submit a bunch of kernels, we can achieve
maximum overlapping between non-dependent data flows on the DAG implicitly deduced from
our <em>buffer accessors</em>. This looks extremely convenient compared to what happens in other
paradigms where, in real world applications, a large amount of effort must be spent to
achieve maximum overlapping between data transfers and kernel executions.</p>

<h4 id="kernels-are-launched-over-a-grid">Kernels are launched over a grid</h4>

<p>The <em>implicit iteration space</em> over which kernels are executed has shape and extent,
just like a CUDA kernel grid. Let&rsquo;s have a look at the <code>parallel_for</code> call
(ignore <code>kernel_tag</code><sup class="footnote-ref" id="fnref:4"><a href="#fn:4">4</a></sup> for now):</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp">    <span style="color:#75715e">// Enqueue parallel kernel
</span><span style="color:#75715e"></span>    cgh.parallel_for<span style="color:#f92672">&lt;</span>kernel_tag<span style="color:#f92672">&gt;</span>(
        cl<span style="color:#f92672">::</span>sycl<span style="color:#f92672">::</span>range<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">1</span><span style="color:#f92672">&gt;</span>{size(result)},  <span style="color:#75715e">// 1st paramater: the kernel grid
</span><span style="color:#75715e"></span>    <span style="color:#75715e">// ...
</span></code></pre></div>
<p>With the first parameter we are saying that the kernel grid will have
<strong>one dimension</strong> (the non-type template parameter) with extent
<code>== size(result)</code>. In the same way as other paradigms work, with the
<code>cl::sycl::range&lt;1&gt;{n}</code> parameter we are launching a 1-dimensional vector
of execution units, one for each of the <code>n</code> output elements.</p>

<p>The SYCL standard brings so much at the stake, interesting bits like <em>device selectors</em>
(customizable objects that decide on which actual device a kernel will be executed), error
handling and reporting, n-dimensional kernel grids, device allocators, device atomics and
<em>a lot more</em>, enough to write entire books on the subject. Just stop here for now, you get
the general idea.</p>

<h2 id="challenges">Challenges</h2>

<p>As clearly <a href="https://youtu.be/KHa-OSrZPGo">pointed out by Justin Lebar</a> (one of the authors
of the clang&rsquo;s PTX backend): <em>CUDA Is a Low Level Language</em>. And that is perfectly
understandable: the accelerated portion of any application is going to be the hottest one,
that kind of hotspot that is usually carefully optimized, likely by hand, iteratively,
with the help of micro-benchmarks and packed with tricks and hacks that privilege
performance over clarity or maintenance and are obviously tightly related to the actual
hardware it targets. While SYCL claims to be <em>portable</em> and <em>cross platform</em>, just look at
the amount of extensions are being introduced to support FPGA targets
(<code>cl::sycl::vendor::xilinx::dataflow</code> for example,
<a href="https://github.com/triSYCL/triSYCL/blob/6e5565f89338a6a74d7283085da980f0c400c57e/tests/pipeline/single_task_vector_add_drt_dataflow_func_local_pipeline.cpp">here</a>
in <code>triSYCL</code>): this is completely normal since FPGAs are weird beasts, radically different
from regular GPGPU architectures and so, in hot, accelerated code this profound difference
stands out clearly.</p>

<p>I think this is going to be a recurring pattern in real world, SYCL-accelerated code
bases: a bunch of different SYCL kernels, each one hand-optimized for a class of
architectures, a single architecture or even a specific product just like happens in CUDA
or OpenCL nowadays. In other words, I would say that SYCL <strong>has not performance
portability among its design goals</strong>.</p>

<p>Despite this unavoidable shortcoming, SYCL still brings a lot of advantages, for example:</p>

<ul>
<li>convenience and developer <em>sanity</em>: it is just C++11 code, no language extensions, no
weird toolchains;</li>
<li>host CPU backends, already available, enable the application to leverage the host
processors as well and from CPU backends comes easy debugging and observability;</li>
<li>a terse and expressive API, miles ahead of the sheer verbosity of OpenCL;</li>
<li>no vendor-lock in; even if NVidia could try to gatekeep <a href="https://www.khronos.org/registry/spir-v/">SPIR-V</a>
(the intermediate assembly representation on top of which SYCL is based) support on
their platform, when in presence of CUDA hardware the compiler could just sidestep
SPIR-V generation and go directly for the PTX backend to natively compile SYCL kernels
for NVidia hardware.</li>
</ul>

<p>Moreover, several open and closed source implementations are already available,
each one with its goals and strenghts:</p>

<ul>
<li><a href="https://github.com/triSYCL/triSYCL">triSYCL</a>, the reference implementation;</li>
<li><a href="https://github.com/illuhad/hipSYCL">hipSYCL</a>;</li>
<li><a href="https://www.codeplay.com/products/computesuite/computecpp">ComputeCpp</a>;</li>
<li><a href="https://github.com/intel/llvm/tree/sycl">clang</a>, actively developed by Intel and aimed at being reintegrated in upstream LLVM.</li>
</ul>

<p>To summarize the ecosystem, I will borrow this chart directly from the
<a href="https://github.com/illuhad/hipSYCL">hipSYCL</a> documentation:</p>

<p><img src="/img/sycl-targets.png" alt="targets" /></p>

<p>Wrapping up, I personally think that the first, realistic, valuable goal that SYCL can
achieve is to estabilish both <strong>a standard platform and a common vocabulary for
heterogeneous systems programming</strong> on which people coming from different industries and
backgrounds can build communities, share code, tooling, build systems and, more
importantly, <strong>break out from vendor lock-ins</strong>.</p>

<p>Of course, the most important question right now is:</p>

<p><em>Will it succeed?</em></p>

<h2 id="look-ma-no-cuda-programming-gpus-with-modern-c-italian-c-meetup">Look ma, no CUDA! Programming GPUs with modern C++ @ Italian C++ Meetup</h2>

<p>During the <a href="https://www.italiancpp.org/event/meetup-maggio2019/">May 2019 meetup</a>
of the <a href="https://twitter.com/italiancpp">Italian C++ Community</a>
in Modena, I gave an introductory talk about the state of the art in GPGPU programming,
the paradigms that emerged in the last ten years and what SYCL brings to the table and why
we should care. You can find all the support material including examples, build scripts
and the slide deck <a href="https://github.com/nazavode/meetupcpp-may-2019">here</a>, feel free to
grab anything you happen to find useful. You can even see me prattle on (<strong>sorry, italian
only</strong>) <a href="https://www.youtube.com/watch?v=c04Y9AUH-xU">here</a>.</p>

<p>Thanks to all the attendees and to <a href="https://twitter.com/ilpropheta">Marco Arena</a>
for the chance to show some brand new cool stuff!</p>

<h2 id="credits">Credits</h2>

<p>A lot of excellent charts, snippets and pitches have been taken directly from publicly
available talks across the net, I&rsquo;ve strived really hard to put proper credits but if you
notice that something&rsquo;s missing please drop a comment or open an issue on
<a href="https://www.italiancpp.org/event/meetup-maggio2019/">the repo</a>.</p>

<p>I&rsquo;m particularly grateful to (in order of appearance during the talk):</p>

<ul>
<li><a href="https://www.karlrupp.net/">Karl Rupp</a></li>
<li><a href="https://wongmichael.com/about/">Michael Wong</a></li>
<li><a href="http://www.aerialmantis.co.uk/">Gordon Brown</a></li>
<li><a href="https://github.com/illuhad">Aksel Alpay</a></li>
</ul>

<p><em>Thank you folks for your help in making my slides more clear and understandable</em>.</p>

<h2 id="resources">Resources</h2>

<ul>
<li><a href="http://sycl.tech/"><code>sycl.tech</code></a>: a comprehensive community platform that collects articles, blog posts, talks and everything related to SYCL that shows up on the web.</li>
<li><a href="https://blog.tartanllama.xyz/sycl/">Accelerating your C++ on GPU with SYCL by Simon Brand</a> - one of the nicest introductions around.</li>
<li><a href="http://cppedinburgh.uk/slides/201607-sycl.pdf">Programming GPUs with SYCL by Gordon Brown</a> - a great introduction to the whys and hows of SYCL.</li>
<li><a href="https://developer.codeplay.com/products/computecpp/ce/guides/sycl-guide?">SYCL Developer Guide by Codeplay</a> - the current lack of learning learning material about SYCL is appalling but this terse developer guide makes the situation a little better.</li>
<li><a href="https://github.com/AerialMantis/cppcon2018-parallelism-class">CppCon 2018: Parallel Programming with Modern C++ by Gordon Brown</a> - a great overview of parallel programming and modern C++.</li>
<li><a href="https://www.khronos.org/assets/uploads/developers/library/2018-evs/EVS2018_09_Modern_Cpp_for_accelerators_andrew.pdf">Modern C++ for accelerators: a SYCL deep dive by Andrew Richards</a> - an excellent slide deck to be printed and studied.</li>
<li><a href="https://youtu.be/rfg19iODkhI">2019 EuroLLVM Developers’ Meeting: A. Savonichev (Intel) &ldquo;SYCL compiler: zero-cost abstraction and type safety for heterogeneous computing&rdquo;</a> - a nice insight on how Intel is working on his own SYCL implementation for LLVM; mandatory for compiler nerds.</li>
<li><a href="https://www.khronos.org/files/sycl/sycl-12-reference-card.pdf">SYCL 1.2.1 API Reference Card</a> - print and hang it on the wall next to the Picasso you just bought at Sotheby&rsquo;s.</li>
<li><a href="https://www.khronos.org/registry/SYCL/">SYCL Standard Specification</a> - to be a proper standard, you need a proper spec. Not so <em>standardese</em> (a traightforward and educational read, actually) but definitely not a novel.</li>
<li><a href="https://gcc.gnu.org/wiki/Offloading">GCC support for offloading to PTX via OpenACC</a></li>
<li><a href="https://llvm.org/docs/CompileCudaWithLLVM.html">Compiling CUDA with clang - LLVM 9 documentation</a></li>
<li><a href="https://youtu.be/KHa-OSrZPGo">CppCon 2016: CUDA is a low-level language by Justin Lebar</a></li>
<li><a href="https://ai.google/research/pubs/pub45226"><code>gpucc</code>: An Open-Source GPGPU Compiler</a></li>
</ul>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1"><p>the SYCL specification is actually based on C++11 but this restriction applies only
to the body of the kernel lambda, e.g. the only code that is going to be actually
compiled by device backends. In the example I used some C++17 library stuff
(<a href="https://en.cppreference.com/w/cpp/iterator/data"><code>std::data()</code></a> for instance),
and it is ok as long as the host frontend supports it.</p>
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>

<li id="fn:2"><p>while totally invisible to the user, the standard specification allows
  two different workflows for compilation:</p>

<ul>
<li><em>separate compilation</em>: a frontend driver splits the C++ source and calls
different device compilers under the hood before linking everything together
in a fat binary;</li>
<li><em>single source compilation</em>: the actual compiler frontend parses the input
translation unit just once (remember that we are dealing just with standard
C++11 code) and then forwards the lowered representation to all the device
backends involved.
For example, <a href="https://github.com/illuhad/hipSYCL">hipSYCL</a> used to rely on
<em>separate compilation</em> using a
<a href="https://github.com/illuhad/hipSYCL/blob/master/bin/syclcc">python script</a>
to carry out all the orchestration work before switching to the
<em>single source compilation</em> strategy via the
<a href="https://github.com/illuhad/hipSYCL/blob/master/bin/syclcc-clang">clang plugin interface</a>.</li>
</ul>
 <a class="footnote-return" href="#fnref:2"><sup>[return]</sup></a></li>

<li id="fn:3"><p>since we are constructing <em>non-owning views</em> (<code>cl::sycl::buffer&lt;T&gt;</code> acts exactly
like a <a href="https://en.cppreference.com/w/cpp/container/span"><code>std::span&lt;T&gt;</code></a> in this regard)
over contiguous chunks of memory that have to be transferred across different address
spaces, make sure that the
<a href="https://en.cppreference.com/w/cpp/named_req/ContiguousContainer"><code>ContiguousContainer</code></a>
concept is satisfied: while we wait for C++20 to bring proper concepts in, we can
reasonably ensure the <em>contiguous storage</em> property just
<a href="https://github.com/microsoft/GSL/blob/1212beae777dba02c230ece8c0c0ec12790047ea/include/gsl/span#L419-L426">like <code>GSL</code> does for <code>gsl::span&lt;T&gt;</code></a>).</p>
 <a class="footnote-return" href="#fnref:3"><sup>[return]</sup></a></li>

<li id="fn:4"><p>the <code>parallel_for</code> function is templated with an (empty) type, in this
case called <code>class AddKernel</code>. This <em>tag</em> is used only to give the
anonymous callable object generated by the lambda expression a unique,
user-defined name on which (possibly) different compilers can agree on.
Look at it as workaround to de-anonymize compiler-generated callable
objects (or a way to have <code>extern</code> lambdas).
<strong>Please note that kernels must abide by
<a href="https://en.wikipedia.org/wiki/One_Definition_Rule">ODR</a>!</strong></p>
 <a class="footnote-return" href="#fnref:4"><sup>[return]</sup></a></li>
</ol>
</div>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://nazavode.github.io/blog/google-benchmark/">Understanding performance with Google Benchmark @ Italian C&#43;&#43; Meetup</a>
      </h1>
      <span class="post-date">Dec 13, 2018 &middot; <a href="https://nazavode.github.io/blog/google-benchmark/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://nazavode.github.io/categories/dev">Dev</a><a class="label" href="https://nazavode.github.io/categories/talk">Talk</a>
      </span>
      
      <p>During the last meetup of the <a href="https://twitter.com/italiancpp">Italian C++ Community</a> in
Modena, Italy I had the chance to give a talk about profiling C++ code. The whole game
boils down to <em>understanding</em> what&rsquo;s going on when you have to cope with <em>very smart</em>
optimizing compilers, NUMA architectures and speculative, superscalar CPUs: in this quest
for knowledge we are lucky enough to have some extremely useful tools like the <em>holy</em>
<code>perf</code> and micro benchmarks, using the excellent
<a href="https://github.com/google/benchmark">Google Benchmark</a> for instance.</p>

<p><strong>It has been a lot of fun!</strong></p>

<p>You can find all the support material including examples and helper scripts
<a href="https://github.com/nazavode/meetupcpp-dec-2018">here</a>, feel free to grab anything
you happen to find useful. Oh, and the slide deck is
<a href="https://nazavode.github.io/meetupcpp-dec-2018/">here</a>.</p>

<p>Thanks to all the attendees and to <a href="https://twitter.com/ilpropheta">Marco Arena</a>
for the chance to prattle on about some fun stuff I enjoy.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://nazavode.github.io/blog/tracboat/">Salvaging 10 years of Trac while moving to GitLab: tooling for a better life</a>
      </h1>
      <span class="post-date">Apr 11, 2017 &middot; <a href="https://nazavode.github.io/blog/tracboat/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://nazavode.github.io/categories/dev">Dev</a><a class="label" href="https://nazavode.github.io/categories/tooling">Tooling</a>
      </span>
      
      <p>Some time ago in my team at work we began considering a complete makeover of our devops
infrastructure. The platform in use was based on <strong><a href="https://trac.edgewall.org/">Trac</a></strong>, a tool that ten
years ago proved itself packed with features, looked great and came in the form of an
open, clear and easily extensible Python code base. Almost <strong>a mandatory choice back
then</strong>. It served us <em>very</em> well (thanks Trac folks!), even when it had to run on
underpowered hardware, without maintenance and under heavy loads. Despite its stability
and practicality, the need for a proper, <em>modern</em> devops platform seamlessly supporting
continuous integration and deployment pipelines, as well as code review, suddenly came
out. <strong>The choice went for <a href="https://gitlab.com/">GitLab</a></strong>, a solution that would have given us
the same degree of freedom (free community edition, open source, easily manageable on
premise) along all the shiny new features we were looking for.</p>

<p>At that point, <strong>the issue of how to migrate all of the content came out</strong>.</p>

<p>At the time every team used the same Trac instance as a <em>knowledge base</em>, with thousands
of wiki pages, GBs of attachments and <strong>ten years of bug hunting chronicles</strong>.</p>

<p>The boss was <em>really scared</em>. To be honest, we were all scared at the idea of loosing
something in the migration process.</p>

<p>Even the remote chance of loosing a single bit of our history was not acceptable and a
risk we weren&rsquo;t keen facing at the point that leaving everything as it was untouched just
out of fear was <em>real</em>. In the face of the risk of giving up on the makeover, I decided I
had to try to do something. The prospect of such a bump in life quality for the whole team
was enough for me to invest one weekend in crafting some tool that would have left no
objections on the table and hopefully all of us with a shiny, new devops platform.</p>

<p><strong>I came up with <a href="https://github.com/tracboat/tracboat">Tracboat</a></strong>, a <strong>command line tool</strong> written in Python
aimed at <strong>migrating an entire Trac instance to GitLab</strong>. It&rsquo;s obviously not perfect: it
has been written in a rush, it&rsquo;s slow (no
<a href="https://docs.python.org/3/library/xmlrpc.client.html#multicall-objects">XML-RPC multicalls</a>),
with little unit testing and the code base definitely needs some love and refactoring, but
<em>it works</em>. And <strong>it worked extremely well for our own migration</strong>.</p>

<p>You can do essentially two of things with the tool:</p>

<ol>
<li><strong>export a Trac instance as a whole in a single <code>json</code> file</strong> including attachments,
wiki pages and issues (maybe piping it into some compressor, <code>json</code> can grow very fast
in size);</li>
<li><strong>import a previously exported instance into a fresh GitLab instance</strong>.</li>
</ol>

<p>It will take care of <strong>attachments</strong> by uploading them and updating links, <strong>translate
wiki pages</strong> from Trac format to markdown and <strong>map Trac users to new GitLab accounts</strong>
(creating them from scratch when needed). By combining those basic operations you can, for
example, migrate a Trac instance directly into GitLab without having to rely on an
intermediate local file.</p>

<p>Unfortunately the lack of spare time forced me to set back any further development despite
the lots of people coming out asking for fixes and new features (yes, a lot of folks are
still using Trac in 2017), so I decided to move the <a href="https://github.com/nazavode">original repository</a>
to a <a href="https://github.com/tracboat">brand new organization</a> and accept the help offered by
the community.</p>

<h2 id="credits">Credits</h2>

<p>The originating idea was taken from <a href="https://github.com/moimael/trac-to-gitlab">trac-to-gitlab</a>
by <a href="https://github.com/moimael">Maël Lavault</a>.</p>

<p>A lot of work has been taken over by <a href="https://github.com/glensc">Elan Ruusamäe</a> that is
now the most active maintainer (thank you!).</p>
      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://nazavode.github.io/blog/aliasing/">Aliasing Explained (Part 1)</a>
      </h1>
      <span class="post-date">Mar 26, 2017 &middot; <a href="https://nazavode.github.io/blog/aliasing/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://nazavode.github.io/categories/dev">Dev</a><a class="label" href="https://nazavode.github.io/categories/languages">Languages</a><a class="label" href="https://nazavode.github.io/categories/c">C</a>
      </span>
      
      <p>Since my job involves a lot of HPC stuff and performance-obsessed code, one of
the first topics I had to dive into was <strong>aliasing in the C standard</strong>. I
found out that it is a subtle topic, quite obscure and very often
overlooked even by the most experienced programmers. This post is an attempt
to clarify the concept of <em>aliasing</em>, why should we care, how it impacts
the code generated by the compiler and how can we master it with no hassle.</p>

<p>So what is an <em>alias</em>? Let&rsquo;s try to clarify this a bit:</p>

<blockquote>
<p>One pointer (<em>lvalue expression</em>) is said to <strong>alias</strong> another pointer when
both refer to the <strong>same location or object</strong></p>
</blockquote>

<p>In practice, an <em>alias</em> involves referring to the same physical entity (an
object stored in memory) through multiple handlers (<em>pointers</em>):</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">int</span> i;
<span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span>ptr1 <span style="color:#f92672">=</span> <span style="color:#f92672">&amp;</span>i;
<span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span>ptr2 <span style="color:#f92672">=</span> <span style="color:#f92672">&amp;</span>i;</code></pre></div>

<p>In this trivial example, <code>ptr1</code> and <code>ptr2</code> are both aliases of each other since
they are pointing to the same object (the integer <code>i</code>).</p>

<p>Just a quick note: even if we are talking about <em>pointers</em> and C-ish stuff,
this concept is valid for <em>all</em> programming languages: a lot of recent languages
use pointers (Go, for example) but in C this issue is a lot more critical since
we can do <em>arithmetics</em> with them, moving pointers around in memory as we like.</p>

<h2 id="why-should-i-care">Why should I care?</h2>

<p>Got it, this is <em>the</em> question. Why should I care about aliasing at all?</p>

<p><em>Short answer</em>: if you are writing code that isn&rsquo;t supposed to be pushed to
its limits in terms of performance, <em>you can ignore aliasing at all and be happy</em>.</p>

<p><em>Long answer</em>: while working on code among whose targets had <em>performance</em>, I
found myself several times blaming the compiler for not having recognized
<em>obvious</em> optimizations thus generating what I thought was crappy assembly code,
translated in a way that was <em>too pedantic</em> for a modern piece of software.
After diving into the obscure topic of <em>aliasing</em>, it obviously turned out that
the problem was me ignoring a quite large slice of the C language.</p>

<p>So, if you want to dive into this, let&rsquo;s start with a trivial example:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">foo</span> (<span style="color:#66d9ef">float</span> <span style="color:#f92672">*</span>out_vector_a, <span style="color:#66d9ef">float</span> <span style="color:#f92672">*</span>out_vector_b, <span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span>in_vector, <span style="color:#66d9ef">int</span> n)
{
    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; i<span style="color:#f92672">&lt;</span>n; <span style="color:#f92672">++</span>i) {
        out_vector_a[i] <span style="color:#f92672">=</span> in_vector[i];
        out_vector_b[i] <span style="color:#f92672">=</span> in_vector[i];
    }
}</code></pre></div>

<p>In this snippet we are doing a simple thing: copying an input memory chunk
(starting at address <code>in_vector</code>), one integer at a time, into two output memory
chunks (starting at addresses <code>out_vector_a</code> and <code>out_vector_b</code>). Pretty
straghtforward, uh? How an harmless snippet like this could be source of
hassles? Let&rsquo;s dive into the x86 assembly code generated by <code>gcc</code> (disassembled
through <code>objdump</code>):</p>

<script type="application/javascript" src="//gist.github.com/nazavode/22326361646ba3cfd24cec3fd9594d49.js?file=example_func_01.s"></script>

<p>Don&rsquo;t let this pile of assembly code scare you, just get the big picture and
focus on the instructions that carry out the actual copies:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">    out_vector_a[i] = in_vector[i];
10:	66 0f ef c0          	pxor     xmm0,xmm0
<span style="display:block;width:100%;background-color:#3c3d38">14:	f3 0f 2a 04 82       	cvtsi2ss xmm0,DWORD PTR [rdx+rax*4]
</span>19:	f3 0f 11 04 87       	movss    DWORD PTR [rdi+rax*4],xmm0
    out_vector_b[i] = in_vector[i];
1e:	66 0f ef c0          	pxor     xmm0,xmm0
<span style="display:block;width:100%;background-color:#3c3d38">22:	f3 0f 2a 04 82       	cvtsi2ss xmm0,DWORD PTR [rdx+rax*4]
</span>27:	f3 0f 11 04 86       	movss    DWORD PTR [rsi+rax*4],xmm0</code></pre></div>

<p>In an attempt to render these instructions in a <em>human friendly</em> way, we can
decode them like this:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">    out_vector_a[i] = in_vector[i];
10:	cleanup vector register xmm0
<span style="display:block;width:100%;background-color:#3c3d38">14:	cast int -&gt; float and load memory location in_vector[i] into xmm0
</span>19:	store xmm0 into memory location out_vector_a[i]
    out_vector_b[i] = in_vector[i];
1e:	cleanup vector register xmm0
<span style="display:block;width:100%;background-color:#3c3d38">22:	cast int -&gt; float and load memory location in_vector[i] into xmm0
</span>27:	store xmm0 into memory location out_vector_b[i]</code></pre></div>

<p>There are no doubts about the first three instructions (<code>10</code>, <code>14</code> and <code>19</code>), we
are actually spending cycles to carry out useful work copying the value
contained in memory at <code>in_vector[i]</code> in the corresponding output memory at
<code>out_vector_a[i]</code> using the register <code>xmm0</code> as a buffer. But what about the
following instructions? We are carrying out <em>exactly</em> the same work again. Take
a look at instruction <code>22</code>: it&rsquo;s the same instruction as <code>14</code>. <em>Exactly the
same</em>. That <code>cvtsi2ss</code> tells the CPU to <em>load the content
of the same memory location</em> as the previous one (<code>[rdx+rax*4]</code>) in <em>the same
vector register</em> (<code>xmm0</code>).</p>

<p><strong>Why are we loading the same data twice? Why the compiler isn&rsquo;t just recycling
the value he loaded just two instructions earlier loading it from memory again
instead?</strong></p>

<p>That is because during the previous store instruction (<code>14</code>) the CPU wrote in a
location inside the boundaries of array <code>out_vector_a</code> and in order to
guarantee semantic correctness, <strong>the compiler must assume that the first store
could have ended up writing in the same area as <code>in_vector</code></strong>, in other words that
<strong><code>out_vector_a</code> could be an alias for <code>in_vector</code></strong>. In order to avoid issues,
it forces the CPU to reload the same data from memory again, so if the location
has been written during the previous instruction, its updated content would be
correctly retrieved in its updated state.</p>

<p>This conservative behavoiur guarantees correctness even in the situation where
the two output memory chunks are actually the same but, of course, in the
majority of situations where the output memory chunks are not overlapped,
performing a load twice means that we are halving our own memory bandwidth and
wasting a lot of clock cycles. How can we help the compiler in doing a better
job?</p>

<h2 id="aliasing-rules">Aliasing rules</h2>

<p>In the <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1548.pdf">ISO C standard document</a> the committee precisely states how we
can access an object or, in other words, <em>what is the type of the pointer that
can legally refer to an object</em>:</p>

<blockquote>
<p>An object shall have its stored value <strong>accessed only by an lvalue
expression</strong> that has one of the <strong>following types</strong>:</p>

<ul>
<li>a <strong>type compatible</strong> with the effective type of the object,</li>
<li>a <strong>qualified version</strong> of a <strong>type compatible</strong> with the effective type of
the object,</li>
<li>a type that is the <strong>signed or unsigned</strong> type corresponding to the
effective type of the object,</li>
<li>a type that is the signed or unsigned type corresponding to a qualified
version of the effective type of the object,</li>
<li>an <strong>aggregate or union</strong> type that includes one of the aforementioned types
among its members (including, recursively, a member of a subaggregate or
contained union), or</li>
<li>a <strong>character</strong> type.</li>
</ul>

<p><em>ISO/IEC 9899:201x, Section 6.5</em></p>
</blockquote>

<p>Don&rsquo;t worry about the definition of <em>compatible types</em>, it turns out to be
exactly what you are thinking of (except for <code>struct</code> and <code>union</code>, but we can
ignore that for now):</p>

<blockquote>
<p>Two types have <em>compatible type</em> if their types are the same.</p>

<p><em>ISO/IEC 9899:201x, Section 6.2.7</em></p>
</blockquote>

<p>So, following the rules, we can have pointers that are aliases in a lot of
different legal ways. For example, these pointers <em>could be</em> valid aliases of
each other:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span>a;
<span style="color:#66d9ef">unsigned</span> <span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span>b;
<span style="color:#66d9ef">char</span> <span style="color:#f92672">*</span>c;

<span style="color:#66d9ef">typedef</span> <span style="color:#66d9ef">union</span> {
    <span style="color:#66d9ef">char</span> c;
    <span style="color:#66d9ef">float</span> f;
} Mask;

Mask <span style="color:#f92672">*</span>d;</code></pre></div>

<p>&hellip;but these couldn&rsquo;t:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">long</span> <span style="color:#f92672">*</span>a;
<span style="color:#66d9ef">double</span> <span style="color:#f92672">*</span>b;</code></pre></div>

<p>Note that a <strong><code>char *</code> is always a potential alias</strong> since <code>char</code> is the minimum
allocation unit in C: all type sizes are specified in <code>char</code> units and <code>char</code>
pointers are how we swipe raw memory (copying chunks regardless of the
underlying object type, for example).</p>

<p>Just a note about terminology: in the ISO C world, <strong>strict aliasing</strong>, <strong>ANSI
aliasing</strong> and <strong>type-based aliasing</strong> are exactly the same thing, they all
refer to the <strong>same concept</strong> (actually they are <em>aliases</em>&hellip;sorry for the
pun :).</p>

<h2 id="exploiting-the-law">Exploiting the law</h2>

<p>So, what about our previous example? We were dealing with two pointers of
incompatible types (<code>int *</code> and <code>float *</code>), so our output arrays (<code>out_vector_a</code>
and <code>out_vector_b</code>) and the input array (<code>in_vector</code>)  aren&rsquo;t legal aliases.
Anyway the compiler treated them as they were, that is because <code>gcc</code> (and almost
all the compilers I&rsquo;ve dealt with) works in a conservative way and assumes that
the programmer doesn&rsquo;t care about aliasing rules and it tries to not to insert
<em>very</em> subtle bugs. Let&rsquo;s try to tell <code>gcc</code> to abide by the standard with
a proper flag (<code>-fstrict-aliasing</code>). This time I&rsquo;ve left out the full assembly
file (find it <a href="https://gist.githubusercontent.com/nazavode/22326361646ba3cfd24cec3fd9594d49/raw/a65080776ef619009a0dff9374d593661eb63563/example_func_02.s">here</a>), give a look to the
interesting lines instead, the ones carrying out the actual copy:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">    out_vector_a[i] = in_vector[i];
10:   66 0f ef c0          	pxor     xmm0,xmm0
<span style="display:block;width:100%;background-color:#3c3d38">14:	f3 0f 2a 04 82       	cvtsi2ss xmm0,DWORD PTR [rdx+rax*4]
</span>19:	f3 0f 11 04 87       	movss    DWORD PTR [rdi+rax*4],xmm0
    out_vector_b[i] = in_vector[i];
1e:	f3 0f 11 04 86       	movss    DWORD PTR [rsi+rax*4],xmm0
23:	48 83 c0 01          	add      rax,0x1</code></pre></div>

<p>This time <strong>the second load disappeared</strong>. Again, let&rsquo;s try to decode the
meaning of the assembly:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">    out_vector_a[i] = in_vector[i];
10:	cleanup vector register xmm0
<span style="display:block;width:100%;background-color:#3c3d38">14:	cast int -&gt; float and load memory location in_vector[i] into xmm0
</span>19:	store xmm0 into memory location out_vector_a[i]
    out_vector_b[i] = in_vector[i];
1e:	store xmm0 into memory location out_vector_b[i]
23:	increment loop counter</code></pre></div>

<p>This is nice: under our own guarantee that <strong>we know what we are doing</strong>, the
compiler loads the memory location once and for the second array it just
retrieves the same value from the <em>buffer</em> register.</p>

<p><strong>We&rsquo;ve just doubled the memory bandwidth available for our copy function.</strong></p>

<p>But what happens when the types of our output and input arrays are
compatible? Let&rsquo;s give it a try:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">foo</span> (<span style="color:#66d9ef">float</span> <span style="color:#f92672">*</span>out_vector_a, <span style="color:#66d9ef">float</span> <span style="color:#f92672">*</span>out_vector_b, <span style="color:#66d9ef">float</span> <span style="color:#f92672">*</span>in_vector, <span style="color:#66d9ef">int</span> n)
{
    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; i<span style="color:#f92672">&lt;</span>n; <span style="color:#f92672">++</span>i) {
        out_vector_a[i] <span style="color:#f92672">=</span> in_vector[i];
        out_vector_b[i] <span style="color:#f92672">=</span> in_vector[i];
    }
}</code></pre></div>

<p>Again, just focus on the instructions carrying out the copy
(full assembly <a href="https://gist.githubusercontent.com/nazavode/22326361646ba3cfd24cec3fd9594d49/raw/a65080776ef619009a0dff9374d593661eb63563/example_func_compatible.s">here</a>):</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">    out_vector_a[i] = in_vector[i];
<span style="display:block;width:100%;background-color:#3c3d38">10:	f3 0f 10 04 82       	movss  xmm0,DWORD PTR [rdx+rax*4]
</span>15:	f3 0f 11 04 87       	movss  DWORD PTR [rdi+rax*4],xmm0
    out_vector_b[i] = in_vector[i];
<span style="display:block;width:100%;background-color:#3c3d38">1a: f3 0f 10 04 82       	movss  xmm0,DWORD PTR [rdx+rax*4]
</span>1f:	f3 0f 11 04 86       	movss  DWORD PTR [rsi+rax*4],xmm0
24:	48 83 c0 01          	add    rax,0x1</code></pre></div>

<p>Apart from tiny differences due to the fact that we are dealing with <code>float</code>
only (no more casts, the instruction that loads from memory is now <code>movss</code>),
we have fallen into the same <em>double load</em> situation:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">    out_vector_a[i] = in_vector[i];
<span style="display:block;width:100%;background-color:#3c3d38">10:	    load memory location in_vector[i] into vector register xmm0
</span>15:	    store xmm0 into memory location out_vector_a[i]
    out_vector_b[i] = in_vector[i];
<span style="display:block;width:100%;background-color:#3c3d38">1a:	    load memory location in_vector[i] into vector register xmm0
</span>1f:     store xmm0 into memory location out_vector_b[i]
24:     increment loop counter</code></pre></div>

<p>Even if we ask the compiler to follow the standard aliasing rules, the use of
<em>compatible types</em> leads to the come back of the extra instruction. What we are
seeing here is that for the standard rules, both output arrays and input array
are pointers of type <code>float</code> (compatible by definition since it&rsquo;s exactly the
same type) so the compiler must assume that they can be <em>aliases</em> to each other
referring to the same object in memory. How can we escape this ditch?</p>

<h2 id="the-restrict-qualifier">The <code>restrict</code> qualifier</h2>

<p>Luckily the standard provides us a tool to tell the compiler <strong>under our own
responsibility</strong> that even if two pointers could be legal aliases, we are
guaranteeing that they aren&rsquo;t:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">foo</span> (<span style="color:#66d9ef">float</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> out_vector_a, <span style="color:#66d9ef">float</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> out_vector_b,
          <span style="color:#66d9ef">float</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> in_vector, <span style="color:#66d9ef">int</span> n)
{
    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; i<span style="color:#f92672">&lt;</span>n; <span style="color:#f92672">++</span>i) {
        out_vector_a[i] <span style="color:#f92672">=</span> in_vector[i];
        out_vector_b[i] <span style="color:#f92672">=</span> in_vector[i];
    }
}</code></pre></div>

<p>We&rsquo;ve just took the same code as in the previous example and added the
<code>restrict</code> qualifier to all pointers. Compiling it with the same <code>gcc</code> options
as before, we end up with the following assembly (you can find the full listing
<a href="https://gist.githubusercontent.com/nazavode/22326361646ba3cfd24cec3fd9594d49/raw/a65080776ef619009a0dff9374d593661eb63563/example_func_compatible.s">here</a>):</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">    out_vector_a[i] = in_vector[i];
<span style="display:block;width:100%;background-color:#3c3d38">10:	f3 0f 10 04 82       	movss  xmm0,DWORD PTR [rdx+rax*4]
</span>15:	f3 0f 11 04 87       	movss  DWORD PTR [rdi+rax*4],xmm0
    out_vector_b[i] = in_vector[i];
1a:	f3 0f 11 04 86       	movss  DWORD PTR [rsi+rax*4],xmm0
2f:	48 83 c0 01          	add    rax,0x1</code></pre></div>

<p>Even this time we are able to let the compiler <strong>drop the second load
instruction</strong>, the only load from memory we have here is at instruction <code>10</code>.
This time we used <strong>the <code>restrict</code> qualifier to tell the
compiler that a restricted pointer has no aliases at all</strong>. Of course the
<a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1548.pdf">standard</a> states precisely the meaning of the <code>restrict</code> qualifier:</p>

<blockquote>
<p>An object that is accessed through a <code>restrict</code>-qualified pointer has a
<strong>special association</strong> with that pointer. This association [&hellip;] requires
that <strong>all accesses to that object use, directly or indirectly, the value of
that particular pointer</strong>.</p>

<p><em>ISO/IEC 9899:201x, Section 6.7.3</em></p>
</blockquote>

<p>In other words, a <code>restrict</code> pointer is the only legal way to access the object
it points to in memory. This kind of <em>special association</em> is the same that for
example links a newly allocated memory chunk to its pointer: since it is
brand new, no other already existing pointer can be an alias for it.</p>

<blockquote>
<p>For example, a statement that assigns a value returned by <code>malloc</code> to a single
pointer establishes this association between the allocated object and the pointer.</p>

<p><em>ISO/IEC 9899:201x, Section 6.7.3</em></p>
</blockquote>

<p>Note that <code>restrict</code> hasn&rsquo;t been designed as a mean to change the code&rsquo;s
behaviour but to allow additional optimizations (actually, compilers are allowed
to completely ignore it):</p>

<blockquote>
<p>The intended use of the <code>restrict</code> qualifier [&hellip;] is to <strong>promote optimization</strong>,
and <strong>deleting all instances of the qualifier</strong> from all preprocessing translation
units composing a conforming program <strong>does not change its meaning
(i.e., observable behavior)</strong>.</p>

<p><em>ISO/IEC 9899:201x, Section 6.7.3</em></p>
</blockquote>

<h3 id="restricted-ownership-there-can-be-only-one">Restricted ownership <em>(there can be only one)</em></h3>

<p>Let&rsquo;s consider the following function definitions:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">bar</span>(<span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> p, <span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> q, <span style="color:#66d9ef">int</span> n)
{
    <span style="color:#66d9ef">while</span> (n<span style="color:#f92672">--</span> <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>) {
        <span style="color:#f92672">*</span>p<span style="color:#f92672">++</span> <span style="color:#f92672">=</span> <span style="color:#f92672">*</span>q<span style="color:#f92672">++</span>;
    }
}

<span style="color:#66d9ef">void</span> <span style="color:#a6e22e">callbar</span>(<span style="color:#66d9ef">void</span>)
{
    <span style="color:#66d9ef">extern</span> <span style="color:#66d9ef">int</span> d[<span style="color:#ae81ff">100</span>];
    bar(d <span style="color:#f92672">+</span> <span style="color:#ae81ff">50</span>, d, <span style="color:#ae81ff">50</span>); <span style="color:#75715e">// Valid!
</span><span style="color:#75715e"></span>    bar(d <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span> , d, <span style="color:#ae81ff">50</span>); <span style="color:#75715e">// Undefined behaviour!
</span><span style="color:#75715e"></span>}</code></pre></div>

<p>In this case we are seeing two different situations:</p>

<ol>
<li>during the first call, even if the memory belongs to the same <code>d</code> array, the
two pointers are swiping two completely disjoint areas, <code>d[50] .. d[99]</code>
through <code>p</code> and <code>d[0] .. d[49]</code> through <code>q</code>. Due to the fact that
<code>restrict</code> ensures unique accesses to <em>objects</em> (the underlying <code>int</code> elements
in this case), each array element is going to be accessed through one and only
one pointer: this code is perfectly legal leading to <strong>defined behaviour</strong>;</li>
<li>during the second call, <code>p</code> accesses <code>int</code> objects in the range
<code>d[1] .. d[50]</code> while <code>q</code> in the range <code>d[0] .. d[49]</code>: all the <code>d</code> array
elements (except for <code>d[0]</code> and <code>d[50]</code>) are going to be accessed through
both pointers. This call breaks the <code>restrict</code> contract leading to <strong>undefined
behaviour</strong>.</li>
</ol>

<p>This example highlights the fact that <em><code>restrict</code> compliance of accesses doesn&rsquo;t
care about timing</em>. For instance, <code>bar</code> iterations during the latter call access
<code>d</code> in the sequence:</p>

<ol>
<li><code>p = d[1]</code>, <code>q = d[0];</code></li>
<li><code>p = d[2]</code>, <code>q = d[1];</code></li>
<li><code>p = d[3]</code>, <code>q = d[2];</code></li>
<li>&hellip;and so on&hellip;</li>
</ol>

<p>The two restricted pointers never access the same element at the same time but,
despite this, we end up with an undefined behaviour anyway: it&rsquo;s like a <em>first
touch ownership claim</em>, the first pointer that touches an element estabilish
the kind of <em>special association</em> with the object the standard talks
about.</p>

<p><em>If inside a block an object is going to be accessed at any point in time
through a restricted pointer, then that pointer becomes the one and only allowed
to access that particular object.</em></p>

<p>There is an exception to this rule though, and it&rsquo;s about <em>read-only accesses</em>.
Take a look to this example:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">foo</span>(<span style="color:#66d9ef">int</span><span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> p, <span style="color:#66d9ef">int</span><span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> q, <span style="color:#66d9ef">int</span><span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> r, <span style="color:#66d9ef">int</span> n)
{
    <span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> n; <span style="color:#f92672">++</span>i) {
        p[i] <span style="color:#f92672">=</span> q[i] <span style="color:#f92672">+</span> r[i];
    }
}

<span style="color:#66d9ef">void</span> <span style="color:#a6e22e">callfoo</span>(<span style="color:#66d9ef">int</span> n)
{
    <span style="color:#66d9ef">int</span> a[n];
    <span style="color:#66d9ef">int</span> b[n];
<span style="display:block;width:100%;background-color:#3c3d38">    foo(a, b, b, n);  <span style="color:#75715e">// Valid!
</span></span><span style="color:#75715e"></span>}</code></pre></div>

<p>In this case, we are accessing elements of array <code>b</code> through two restricted
pointers (arguments <code>q</code> and <code>r</code>) at the same time but, unlike in the previous
example, now we are doing read-only accesses since we are writing elements
belonging to the (non overlapping) array <code>a</code> only: in this situation, what we are
getting is a completely <em>well defined behaviour</em>. So, we can now reformulate the
restricted ownership rule we saw in the previous example taking into account
this aspect as well:</p>

<p><strong>If inside a block an object is going to be written at any point in time
through a restricted pointer, then that pointer becomes the one and only allowed
to access (both reading and writing) that particular object.</strong></p>

<h3 id="assignment-between-restrict-pointers">Assignment between <code>restrict</code> pointers</h3>

<p>The standard is so harsh about <code>restrict</code> that even producing a pointer
alias to a restricted one (inside the same block) is <strong>undefined behaviour</strong>:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> q;
<span style="display:block;width:100%;background-color:#3c3d38"><span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> p <span style="color:#f92672">=</span> q; <span style="color:#f92672">//</span> UNDEFINED BEHAVIOUR<span style="color:#f92672">!!!</span></span></code></pre></div>

<p>Note that the rule limiting assignments between restricted pointers does not
distinguish between a function call and an equivalent nested block.
However, there is one exception to the rule: only <strong>outer-to-inner</strong> assignments
between restricted pointers declared in nested blocks have defined behavior:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c">{
    <span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> foo;
    <span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> bar;
    foo <span style="color:#f92672">=</span> bar; <span style="color:#75715e">// undefined behaviour
</span><span style="color:#75715e"></span>    {
<span style="display:block;width:100%;background-color:#3c3d38">        <span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> foo_inner <span style="color:#f92672">=</span> foo; <span style="color:#75715e">// OK: outer-to-inner
</span></span><span style="display:block;width:100%;background-color:#3c3d38"><span style="color:#75715e"></span>        <span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">restrict</span> bar_inner <span style="color:#f92672">=</span> bar; <span style="color:#75715e">// OK: outer-to-inner
</span></span><span style="color:#75715e"></span>        foo <span style="color:#f92672">=</span> bar_inner;                <span style="color:#75715e">// undefined behaviour
</span><span style="color:#75715e"></span>        bar_inner <span style="color:#f92672">=</span> foo_inner;          <span style="color:#75715e">// undefined behaviour
</span><span style="color:#75715e"></span>    }
}</code></pre></div>

<h2 id="what-happens-in-other-languages">What happens in other languages</h2>

<p>Since we are talking about <em>references</em> and <em>objects in memory</em>, aliasing is a
concept common to all programming languages. In the modern ones, this issue is
often ignored (preventing any optimization, obviously) or just carefully handled
by the language definition itself (Rust for example does it in a brilliant way).
But what happens in some <em>classic</em> languages?</p>

<h3 id="aliasing-in-c">Aliasing in <code>C++</code></h3>

<p>Of course <code>C++</code> is a different language than <code>C</code>, but it inherited a lot of
rules from the latter. Aliasing is no exception, the rules are the same with
some additions: the concept of <em>compatible types</em> is extended to <strong>compatible
dynamic types</strong>.</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#66d9ef">class</span><span style="color:#960050;background-color:#1e0010"> </span><span style="color:#a6e22e">A</span>{ A <span style="color:#66d9ef">operator</span> <span style="color:#f92672">+</span>(<span style="color:#66d9ef">const</span> A<span style="color:#f92672">&amp;</span> a) <span style="color:#66d9ef">const</span>; };
<span style="color:#66d9ef">class</span><span style="color:#960050;background-color:#1e0010"> </span><span style="color:#a6e22e">B</span> <span style="color:#f92672">:</span> A {};

<span style="display:block;width:100%;background-color:#3c3d38"><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">foo</span> (A<span style="color:#f92672">*</span> ip1, B<span style="color:#f92672">*</span> ip2, <span style="color:#66d9ef">int</span> n) {
</span>  <span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> n; <span style="color:#f92672">++</span>i) {
    ip1[i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">=</span> ip2[i] <span style="color:#f92672">+</span> ip2[i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>];
  }
}
</code></pre></div>

<p>Disclaimer: I know that this example is actually crap, remember that in <em>modern</em>
<code>C++</code>, direct use of raw pointers is
<a href="https://herbsutter.com/elements-of-modern-c-style/">considered a bad practice</a>.</p>

<p>In this case, the function parameters <code>ip1</code> and <code>ip2</code> are legal aliases of each
other since class <code>B</code> is a subclass of <code>A</code>. Anyway, in <code>C++</code> we have templates:
two types generated from the same template while using different template
parameters are considered non-compatible types.</p>

<h3 id="aliasing-in-fortran">Aliasing in <code>FORTRAN</code></h3>

<p>People doing numerical stuff do love <code>FORTRAN</code>, and for good reasons: it is
carefully cut for their needs, designed from the ground up for number crunching.
And people doing numerical stuff do love saying that <code>FORTRAN</code> is faster
than any other language they ever tried (or just read about, usually they think
is enough). Well, this is obviously not true, especially when comparing
<code>FORTRAN</code> and <code>C</code>. There is a caveat though: if you don&rsquo;t know the <code>C</code> language,
during casual use it&rsquo;s likely that compiled <code>FORTRAN</code> will produce faster
assembly code. There&rsquo;s a reason of course: regarding aliasing, the designers
took the easy way <em>forbidding it at all</em>. <strong>Aliasing in <code>FORTRAN</code> is strictly
forbidden</strong>, except for read-only references.</p>

<p>So, a function like the following:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fortran" data-lang="fortran"><span style="color:#66d9ef">SUBROUTINE </span>f (A, B)
  <span style="color:#66d9ef">INTEGER</span>, <span style="color:#66d9ef">DIMENSION</span>(<span style="color:#f92672">*</span>), <span style="color:#66d9ef">INTENT</span>(INOUT) <span style="color:#66d9ef">::</span> A
  <span style="color:#66d9ef">INTEGER</span>, <span style="color:#66d9ef">DIMENSION</span>(<span style="color:#f92672">*</span>), <span style="color:#66d9ef">INTENT</span>(OUT)   <span style="color:#66d9ef">::</span> B
  <span style="color:#66d9ef">INTEGER</span> <span style="color:#66d9ef">::</span> I

  <span style="color:#66d9ef">DO </span>I<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,LEN(A):
    A(I) <span style="color:#f92672">=</span> A(I<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>
    B(I) <span style="color:#f92672">=</span> A(I) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>
  ENDDO
<span style="color:#66d9ef">END SUBROUTINE</span></code></pre></div>

<p>&hellip;cannot be called in this way:</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Fortran" data-lang="Fortran"><span style="color:#66d9ef">INTEGER</span>, <span style="color:#66d9ef">DIMENSION</span>(<span style="color:#ae81ff">100</span>) <span style="color:#66d9ef">::</span> Arr

<span style="color:#66d9ef">CALL </span>f(Arr, Arr)  <span style="color:#960050;background-color:#1e0010">!</span> <span style="color:#f92672">&lt;--</span> UNDEFINED BEHAVIOUR</code></pre></div>

<p>The fact that we are passing the <em>same</em> reference to both the parameters yields
an <strong>undefined behaviour</strong> with its load of potentially mind crushing bugs.</p>

<h2 id="to-be-continued">To be continued&hellip;</h2>

<p>We will dive deeper in more <em>outer-to-inner</em> rule corollaries, <em>pointer
hierarchies</em> and <em>memory windows</em> in the next post (coming soon).</p>

<hr />

<p>Resources:</p>

<ul>
<li><a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1548.pdf">ISO/IEC 9899:201x</a></li>
<li><a href="https://gist.github.com/nazavode/22326361646ba3cfd24cec3fd9594d49">All examples, including build and objdump scripts</a></li>
</ul>
      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://nazavode.github.io/blog/first/">Move on</a>
      </h1>
      <span class="post-date">Dec 17, 2015 &middot; <a href="https://nazavode.github.io/blog/first/#disqus_thread">Comments</a>
      </span>
      
      <p>Just moved my <a href="https://devnone.wordpress.com">old blog</a> to the combo that mixes
<a href="https://pages.github.com/">GitHub Pages</a> and the amazing
<a href="https://gohugo.io/">Hugo</a> static site generator.</p>

<p>The porting process is actually painless: checkout one of the beautifully
crafted themes (I opted for <a href="https://github.com/zyro/hyde-x">hyde-x</a> that looks
clean enough), tweak it a bit to fit your needs, convert your Wordpress posts
through an <a href="https://domchristie.github.io/to-markdown/">html to Markdown
converter</a> and push everything to
the proper <a href="https://github.com/nazavode/nazavode.github.io">GitHub repo</a>.</p>

<p>The result is very promising.</p>

      
    </div>
    
    

<ul class="pagination">
    
    <li class="page-item">
        <a href="/" class="page-link" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
    </li>
    
    <li class="page-item disabled">
    <a href="" class="page-link" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
    </li>
    
    
    
    
    
    
    
        
        
    
    
    <li class="page-item active"><a class="page-link" href="/">1</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/page/2/">2</a></li>
    
    
    <li class="page-item">
    <a href="/page/2/" class="page-link" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
    </li>
    
    <li class="page-item">
        <a href="/page/2/" class="page-link" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
    </li>
    
</ul>

  </div>
</div>


<script type="text/javascript">
var disqus_shortname = "nazavodeio";
(function () {
    var s = document.createElement('script'); s.async = true;
    s.type = 'text/javascript';
    s.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>


</body>
</html>

